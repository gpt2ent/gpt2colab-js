{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"GPT2_with_Javascript_interface_POC.ipynb\"",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpt2ent/gpt2colab-js/blob/multisample/transformers_js_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMMtepKIwxR8"
      },
      "source": [
        "#This is proof of concept that transformers-based language models can be run from colab with Javascript interface\n",
        "**Q: How to do?**\n",
        "\n",
        "A: \n",
        "1. Runtime -> Change runtime type -> Hardware accelerator -> GPU (or TPU if required)\n",
        "2. Runtime -> Reset all runtimes\n",
        "3. Runtime -> Run all\n",
        "4. Scroll down and wait until you see the little window\n",
        "5. Type text\n",
        "6. The button \"Continue with Transformer\" will invoke Transformer and it will continue your text.\n",
        "\n",
        "**Q: how do I choose a different model?**\n",
        "\n",
        "A: look for `model_name` in the first lines of code. You can use any model name from https://huggingface.co/models?pipeline_tag=text-generation here. However the code can't double-check you for potential out-of-memory situations, so good luck with that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGUX9yKxnaRe"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "spinner_speed = \"1000ms\"\n",
        "\n",
        "# choose model\n",
        "#model_name = 'EleutherAI/gpt-neo-1.3B'\n",
        "#model_name = 'EleutherAI/gpt-neo-2.7B'\n",
        "#model_name = 'sberbank-ai/rugpt3large_based_on_gpt2'\n",
        "#model_name = 'gpt2-xl'\n",
        "model_name = 'gpt2-large'\n",
        "\n",
        "do_sample = True\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "max_total_tokens = 1024  # maximum model sequence length\n",
        "\n",
        "def trim_tensor_max_tokens(tensor, max_length):\n",
        "    \"\"\"\n",
        "    Trim tokenizer output tensor from the beginning, so it can allow to\n",
        "    generate a required amount of tokens.\n",
        "    This is a more precise approach to trimming the beginning of a text.\n",
        "    \"\"\"\n",
        "    tensor = tensor[0] # tokenizer returns tensor with shape (1, len)\n",
        "    tensor = tensor[-(max_total_tokens-max_length):]\n",
        "    tensor = tensor.unsqueeze(0) #back to (1, len) shape as in numpy.expand_dims\n",
        "    return tensor\n",
        "\n",
        "\n",
        "import google.colab.output\n",
        "\n",
        "import json\n",
        "\n",
        "class JsonRepr:\n",
        "    \"\"\"\n",
        "    For some reasons I can only use the result of __repr__\n",
        "    from inside Javascript. So this wrapper uses json.dumps() as __repr__\n",
        "    for python function output.\n",
        "    \"\"\"\n",
        "    def __init__(self, obj):\n",
        "      self.obj = obj\n",
        "\n",
        "    def __repr__(self):\n",
        "      return json.dumps(self.obj)\n",
        "\n",
        "def overlap(a, b):\n",
        "    return max(i for i in range(len(b)+1) if a.endswith(b[:i]))\n",
        "\n",
        "\n",
        "def ai_generate(prefix, temp, top_k, length):\n",
        "\n",
        "    temp = float(temp)\n",
        "    top_k = int(top_k)\n",
        "    length = int(length)\n",
        "\n",
        "    #convert prefix to tokens\n",
        "    tokens = tokenizer(prefix, return_tensors='pt')['input_ids']\n",
        "    tokens = trim_tensor_max_tokens(tokens, length)\n",
        "\n",
        "    output = model.generate(tokens, min_length=tokens.shape[1]+length,\n",
        "                                    max_length=tokens.shape[1]+length,\n",
        "                                    do_sample=do_sample,\n",
        "                                    temperature=temp,\n",
        "                                    top_k=top_k,\n",
        "                                    num_return_sequences=10)\n",
        "    \n",
        "\n",
        "    \n",
        "    result = [tokenizer.decode(output[i,:]) for i in range(10)]\n",
        "    \n",
        "    for i, elem in enumerate(result):\n",
        "        j = overlap(prefix, elem)\n",
        "        result[i] = result[i][j:]\n",
        "    \n",
        "    \n",
        "    return JsonRepr(result)\n",
        "\n",
        "#register callback for Javascript\n",
        "google.colab.output.register_callback('ai_generate', ai_generate)\n",
        "\n",
        "print('Done')\n",
        "\n",
        "# ai_generate('My name is Julien and I like to', '1.0', '100', '100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnSoPbupzOq7"
      },
      "source": [
        "import numpy as np\n",
        "def get_sorted_tokens(model, tokenizer, prefix):\n",
        "    tokens = tokenizer(prefix, return_tensors='pt')['input_ids']\n",
        "    tokens = trim_tensor_max_tokens(tokens, 1)\n",
        "    result = model(tokens)['logits'].detach().numpy()\n",
        "    lastword = result[0,-1]\n",
        "    indices = np.argsort(lastword)[::-1]\n",
        "    \n",
        "    result = [(index, tokenizer.decode([index]), lastword[index]) for index in indices]\n",
        "    return result\n",
        "\n",
        "def js_tokens_callback(prefix):\n",
        "    tokens = get_sorted_tokens(model, tokenizer, prefix)\n",
        "    result = \"\"\"<table class=\"pure-table\"><tr><th>Token</th><th>Index</th><th>Strength</th></tr>\"\"\"\n",
        "    for index, token, strength in tokens[:50]:\n",
        "        result += f\"<tr><td>{token}</td><td>{index}</td><td>{strength:.4f}</td></tr>\"\n",
        "\n",
        "    result += \"</table>\"\n",
        "    return result\n",
        "\n",
        "google.colab.output.register_callback('toptokens', js_tokens_callback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdyRipC0o8vR"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "#spinner from https://codepen.io/vovchisko/pen/vROoYQ\n",
        "spinner_css = \"\"\"\n",
        "<style>\n",
        "@keyframes c-inline-spinner-kf {\n",
        "  0% {\n",
        "    transform: rotate(0deg);\n",
        "  }\n",
        "  100% {\n",
        "    transform: rotate(360deg);\n",
        "  }\n",
        "}\n",
        "\n",
        ".c-inline-spinner,\n",
        ".c-inline-spinner:before {\n",
        "  display: inline-block;\n",
        "  width: 11px;\n",
        "  height: 11px;\n",
        "  transform-origin: 50%;\n",
        "  border: 2px solid transparent;\n",
        "  border-color: #74a8d0 #74a8d0 transparent transparent;\n",
        "  border-radius: 50%;\n",
        "  content: \"\";\n",
        "  animation: linear c-inline-spinner-kf \"\"\"+spinner_speed+\"\"\" infinite;\n",
        "  position: relative;\n",
        "  vertical-align: inherit;\n",
        "  line-height: inherit;\n",
        "}\n",
        ".c-inline-spinner {\n",
        "  top: 3px;\n",
        "  margin: 0 3px;\n",
        "}\n",
        ".c-inline-spinner:before {\n",
        "  border-color: #74a8d0 #74a8d0 transparent transparent;\n",
        "  position: absolute;\n",
        "  left: -2px;\n",
        "  top: -2px;\n",
        "  border-style: solid;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "input_form = \"\"\"\n",
        "<link rel=\"stylesheet\" href=\"https://unpkg.com/purecss@1.0.1/build/pure-min.css\" integrity=\"sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47\" crossorigin=\"anonymous\">\n",
        "\n",
        "<div style=\"background-color:white; border:solid #ccc; width:1200px; padding:20px; color: black;\">\n",
        "<p>You have currently loaded %s model</p>\n",
        "<div class=\"pure-g\">\n",
        "<div class=\"pure-u-2-3\">\n",
        "<textarea id=\"main_textarea\" cols=\"70\" rows=\"20\" style=\"font-family: 'Liberation Serif', 'DejaVu Serif', Georgia, 'Times New Roman', Times, serif; font-size: 13pt; padding:10px;\"></textarea><br>\n",
        "<div class=\"pure-form pure-form-aligned\">\n",
        "    <div class=\"pure-control-group\">\n",
        "      <label for=\"temp\">Temperature:</label>\n",
        "      <input type=\"number\" min=\"0.00\" max=\"999.99\" step=\"0.01\" id=\"temp\" value=\"0.70\" style=\"background-color: white;\">\n",
        "    </div>\n",
        "    <div class=\"pure-control-group\">\n",
        "        <label for=\"top_k\">top_k:</label>\n",
        "        <input type=\"number\" min=\"0\" max=\"9999\" id=\"top_k\" value=\"40\" style=\"background-color: white;\">\n",
        "    </div>\n",
        "    <div class=\"pure-control-group\">\n",
        "        <label for=\"length\">Generate how much:</label>\n",
        "        <input type=\"number\" id=\"length\" min=\"1\" max=\"1023\" value=\"10\" style=\"background-color: white;\">\n",
        "    </div>\n",
        "    <div style=\"width: 600px; display: block; margin-left: auto !important; margin-right: auto !important;\">\n",
        "        <p>\n",
        "          <button class=\"pure-button\" style=\"font-size: 125%%;\" onclick=\"prev()\">Prev</button>\n",
        "          <button class=\"pure-button pure-button-primary\" style=\"font-size: 125%%;\" onclick=\"generate()\">Continue with Transformer</button>\n",
        "          <button class=\"pure-button\" style=\"font-size: 125%%;\" onclick=\"next()\">Next</button>\n",
        "          <span id=\"gen-index\"></span>\n",
        "          <span class=\"c-inline-spinner\" style=\"visibility: hidden;\" id=\"spinner\"></span>\n",
        "        </p>\n",
        "    </div>\n",
        "\n",
        "</div>\n",
        "</div>\n",
        "<div class=\"pure-u-1-3\">\n",
        "<p>Top 50 tokens</p>\n",
        "<div id=\"top_tokens\" style=\"overflow-y: scroll; height: 550px;\"></div>\n",
        "<button class=\"pure-button\" style=\"font-size: 125%%;\" onclick=\"toptokens()\">Get top tokens</button>\n",
        "</div>\n",
        "</div>\n",
        "</div>\n",
        "\"\"\" % model_name\n",
        "\n",
        "javascript = \"\"\"\n",
        "<script type=\"text/Javascript\">\n",
        "\n",
        "    var memory;\n",
        "    var current_index = -1;\n",
        "\n",
        "    function switch_to(new_index, force=false) {\n",
        "        if (current_index == -1 && !force) {\n",
        "            return;\n",
        "        }\n",
        "\n",
        "        new_index = Math.max( Math.min(new_index, 9) , 0);\n",
        "\n",
        "        if (new_index == current_index) {\n",
        "            return;\n",
        "        }\n",
        "\n",
        "        var current_text = document.getElementById('main_textarea').value;\n",
        "        \n",
        "        if (current_index != -1) {\n",
        "            memory[current_index] = current_text;\n",
        "        }\n",
        "        current_index = new_index;\n",
        "        document.getElementById('main_textarea').value = memory[new_index];\n",
        "        document.getElementById('gen-index').innerHTML = new_index+1 + \"/10\";\n",
        "    };\n",
        "\n",
        "    function clear_memory() {\n",
        "      memory = undefined;\n",
        "      current_index = -1;\n",
        "      document.getElementById('gen-index').innerHTML = \"\";\n",
        "    }\n",
        "\n",
        "    function store_gen_results(jsonstring) {\n",
        "        var deftext = document.getElementById('main_textarea').value;\n",
        "        memory = JSON.parse(jsonstring).map(x => deftext+x);\n",
        "        switch_to(0, true);\n",
        "    };\n",
        "\n",
        "    //TODO\n",
        "    function block_arrows() {};\n",
        "\n",
        "    function prev() {switch_to(current_index-1)};\n",
        "    function next() {switch_to(current_index+1)};\n",
        "\n",
        "    \n",
        "\n",
        "    function generate(){\n",
        "        var prefix = document.getElementById('main_textarea').value;\n",
        "        var temp = document.getElementById('temp').value;\n",
        "        var top_k = document.getElementById('top_k').value;\n",
        "        var length = document.getElementById('length').value;\n",
        "        \n",
        "        var kernel = google.colab.kernel;\n",
        "        var resultPromise = kernel.invokeFunction(\"ai_generate\", [prefix,temp,top_k,length]); // developer, look here\n",
        "        resultPromise.then(\n",
        "            function(value) {\n",
        "              store_gen_results(value.data[\"text/plain\"]);\n",
        "              document.getElementById('spinner').style = \"visibility: hidden;\";\n",
        "        });\n",
        "        document.getElementById('spinner').style = \"visibility: visible;\";\n",
        "        \n",
        "        clear_memory();\n",
        "        block_arrows();\n",
        "\n",
        "    };\n",
        "\n",
        "    function toptokens(){\n",
        "      var prefix = document.getElementById('main_textarea').value;\n",
        "      var kernel = google.colab.kernel;\n",
        "      var resultPromise = kernel.invokeFunction(\"toptokens\", [prefix]);\n",
        "      document.getElementById('top_tokens').innerHTML = \"<p>Working...</p>\";\n",
        "      resultPromise.then(\n",
        "        function(value) {\n",
        "            document.getElementById('top_tokens').innerHTML = value.data[\"text/plain\"];\n",
        "        }\n",
        "      );\n",
        "    };\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "HTML(spinner_css + input_form + javascript)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}